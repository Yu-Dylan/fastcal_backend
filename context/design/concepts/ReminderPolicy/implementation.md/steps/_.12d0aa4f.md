---
timestamp: 'Thu Oct 16 2025 21:50:18 GMT-0400 (Eastern Daylight Time)'
parent: '[[..\20251016_215018.8437ba69.md]]'
content_id: 12d0aa4f7ae35af98d26cd8ac8929a9769d30547af25a34aba934486cb8c1134
---

# Documentation

Every concept should have inline documentation and commenting:

* The concept itself should be paired with its purpose.
* The state should be described next to any types.
* Any testing should be guided by the principle.
* Each action should state the requirements and effects, and tests should check that both work against variations.

\<concept\_spec>
concept ReminderPolicy \[User, Policy]

purpose
manage reusable reminder templates that adapt to user behavior and event types

principle
after selecting a policy for an event type, generates personalized reminders based on learned patterns;
users define default policies with timing rules (e.g., 24 hours before, 30 minutes before);
system learns from user behavior (early dismissals, snoozes) and adjusts future reminder times;
policies are matched to events via tags, with personalization applied during instantiation

operational principle
after user creates a policy "Class Reminders" for tag "class" with rules (24 hours before: email, 30 minutes before: notification),
user attaches "class" tag to an event starting at 2pm tomorrow;
selectPolicy returns "Class Reminders";
instantiate generates reminders at 2pm today (email) and 1:30pm tomorrow (notification);
over time, user dismisses 30-min notifications early;
learn() records that 45-min offset is more effective;
future instantiate() calls blend 30min rule with 45min learned offset based on effectiveness score

state
a set of Policy with
a user User
a name String
tags Set<Tag>
rules Sequence<Rule> // ordered list of reminder rules

```
where Rule has
    an offset Number // minutes before event
    a type ReminderType // "notification", "email", "sms"

a set of Personalization with
    a user User
    a tag Tag
    an avgOffset Number // learned average offset in minutes
    an effectiveness Float // 0.0-1.0 score for personalization effectiveness

a set of DefaultPolicy with
    a user User
    a tag Tag
    a policy Policy // default policy for this user-tag combination

invariants
    every Policy belongs to exactly one user
    offset values are positive numbers
    effectiveness scores are between 0.0 and 1.0
    every Rule in a policy has a valid ReminderType
    if DefaultPolicy exists for (user, tag), policy must have that tag in its tags set
```

actions
createPolicy(user: User, name: String, tags: Set<Tag>, rules: Sequence<Rule>): Policy
requires name is non-empty, rules is non-empty, all offsets are positive
effect creates new policy and sets as default for tags if no default exists
note returns the created policy ID

```
selectPolicy(user: User, tags: Set<Tag>): Policy?
    requires tags is non-empty
    effect finds policy matching most tags; checks default policies if no exact match
    note returns best matching policy or none if no policy matches
    note prioritizes policies with maximum tag overlap

instantiate(user: User, policy: Policy, eventStart: DateTime): Sequence<Reminder>
    requires policy exists, policy belongs to user
    effect generates reminders by applying policy rules with personalization adjustments
    note blends rule offset with learned offset based on effectiveness score
    note returns list of reminders with absolute times and types

learn(user: User, tag: Tag, actualOffset: Number, wasEffective: Boolean)
    requires actualOffset is positive
    effect updates personalization data using exponential moving average
    note increases effectiveness score if wasEffective, decreases otherwise
    note creates new personalization entry if none exists for (user, tag)

getPolicy(policy: Policy): Map<String,Any>
    requires policy exists
    effect returns policy data including name, tags, and rules

getUserPolicies(user: User): Set<Policy>
    effect returns all policies for the user

updatePolicy(policy: Policy, name: String?, rules: Sequence<Rule>?)
    requires policy exists, if rules provided then non-empty
    effect updates policy name and/or rules
    note does not affect existing reminders, only future instantiations

deletePolicy(policy: Policy)
    requires policy exists
    effect removes policy and any default policy mappings for this policy
    note does not affect existing reminders that were already instantiated

setDefaultPolicy(user: User, tag: Tag, policy: Policy)
    requires policy exists, policy belongs to user, tag is in policy tags
    effect sets policy as default for (user, tag) combination
    note replaces any existing default for this combination

getPersonalization(user: User, tag: Tag): Map<String,Any>?
    effect returns personalization data for (user, tag) or none if not learned
```

notes
Reminder generation uses adaptive blending:
\- Initial effectiveness is 0.5 (50% rule, 50% learned)
\- As effectiveness increases toward 1.0, learned offset dominates
\- If effectiveness decreases toward 0.0, rule offset dominates
\- Formula: adjustedOffset = ruleOffset × (1 - effectiveness) + learnedOffset × effectiveness

```
Learning adapts to user behavior:
- Early dismissals suggest longer lead time needed
- Snoozes suggest shorter lead time appropriate
- Learning rate (alpha = 0.3) balances stability and adaptation
- Effectiveness adjusts ±0.1 per feedback event

Policy selection prioritizes specificity:
- Exact tag matches preferred over partial matches
- Number of matching tags determines best policy
- Default policies serve as fallback for common tags

ReminderType determines delivery mechanism:
- "notification": push notification to device
- "email": email sent to user
- "sms": text message (requires phone number)

Tags enable flexible policy application:
- Common tags: "class", "meeting", "appointment", "deadline", "birthday"
- Users can define custom tags for specific needs
- Multiple tags allow policy selection based on event characteristics
```

\</concept\_spec>

Please implement the ReminderPolicy concept following the specification above and the implementation guidelines.

Key requirements:

* Use MongoDB collections with PREFIX namespace separation
* Define internal types: Policy, Rule (with offset and type), Reminder
* Implement learning algorithm with exponential moving average (alpha = 0.3)
* Handle personalization blending: adjustedOffset = ruleOffset × (1 - effectiveness) + learnedOffset × effectiveness
* Policy selection should find best match by tag overlap
* Use proper TypeScript types with ID type from @utils/types.ts
* Follow the pattern shown in LikertSurvey example
* Include clear JSDoc comments for complex logic (especially learning and instantiation)
* Handle error cases appropriately

The concept should export a class with all actions as methods.
